{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test the functions of get cpmm arbs\n",
    "- Get a graph representation of the pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import get_cpmm_arb_txn as carb\n",
    "import torch\n",
    "\n",
    "def test_cpmm_arb():\n",
    "    carb.get_cpmm_data('./one_day_arb.csv')\n",
    "    carb.generate_graph_coo('./one_day_arb.csv','../arb_data/pool_info.csv')\n",
    "    carb.generate_graph_input('./one_day_arb.csv','../arb_data/pools.csv',16086270)\n",
    "    carb.generate_graph_output('./one_day_arb.csv','../arb_data/pools.csv',16090709,30)\n",
    "\n",
    "# COO format of graph, represent the edges\n",
    "def get_edge_index():\n",
    "    graph_coo=carb.generate_graph_coo('./one_day_arb.csv','./pool_info.csv')\n",
    "    return torch.tensor(graph_coo,dtype=torch.long)\n",
    "\n",
    "# get node features x (input)\n",
    "def get_x(blocknumber):\n",
    "    x=carb.generate_graph_input('./one_day_arb.csv','./pools.csv',blocknumber)\n",
    "    return torch.tensor(x,dtype=torch.float)\n",
    "\n",
    "# get node targets y (output)\n",
    "def get_y(blocknumber, period=50):\n",
    "    y=carb.generate_graph_output('./one_day_arb.csv','./pools.csv',blocknumber,period)\n",
    "    return torch.tensor(y,dtype=torch.long)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test of a PyG `Data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph COO...\n",
      "number of nodes:489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [03:25<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges in graph: 156\n",
      "generating graph input...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:00<00:00, 39126.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the graph input signal:  (489, 630)\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.85691961e-20]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.52986602e-14]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.59581835e-13]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.00000000e+00\n",
      "  0.00000000e+00 2.86897843e-10]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 ... 1.00000000e+00\n",
      "  0.00000000e+00 1.05925984e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.92902469e-14]]\n",
      "generating graph output...\n",
      "Data(x=[489, 630], edge_index=[2, 156], y=[489, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "graph_edges=get_edge_index()\n",
    "\n",
    "blocknumber=16086270\n",
    "data = Data(edge_index=graph_edges,x=get_x(blocknumber),y=get_y(blocknumber))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create my own dataset\n",
    "- The key step is the method `process`\n",
    "- In `process`, the raw data is parsed into a list of PyG `Data` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph COO...\n",
      "number of nodes:489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [03:24<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges in graph: 156\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m         data, slices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate(data_list)\n\u001b[1;32m     51\u001b[0m         torch\u001b[39m.\u001b[39msave((data, slices), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 53\u001b[0m dataset\u001b[39m=\u001b[39mMyOwnDataset(\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     54\u001b[0m \u001b[39m# process data and save\u001b[39;00m\n\u001b[1;32m     55\u001b[0m dataset\u001b[39m.\u001b[39mprocess()\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mMyOwnDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_filter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n\u001b[1;32m      8\u001b[0m     \u001b[39m# load data from the save path using `process`\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:57\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.9/site-packages/torch_geometric/data/dataset.py:97\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_process:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.9/site-packages/torch_geometric/data/dataset.py:230\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    229\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 230\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    232\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36mMyOwnDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m data_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     37\u001b[0m graph_edges\u001b[39m=\u001b[39mget_edge_index()\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfor\u001b[39;00m blocknumber \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39;49m(start_block_num,end_block_num)):\n\u001b[1;32m     40\u001b[0m     data \u001b[39m=\u001b[39m Data(edge_index\u001b[39m=\u001b[39mgraph_edges,x\u001b[39m=\u001b[39mget_x(blocknumber),y\u001b[39m=\u001b[39mget_y(blocknumber,duration))\n\u001b[1;32m     41\u001b[0m     data_list\u001b[39m.\u001b[39mappend(data)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "        # load data from the save path using `process`\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    # return raw data file names\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['./one_day_arb.csv']\n",
    "\n",
    "    # return the name when saving the dataset files with method `process`\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    # no need, this is for downloading dataset from the web\n",
    "    # def download(self):\n",
    "    #     # Download to `self.raw_dir`.\n",
    "    #     download_url(url, self.raw_dir)\n",
    "    #     ...\n",
    "\n",
    "    # methods to create the dataset\n",
    "    def process(self):\n",
    "        \n",
    "        # Read data into huge PyG `Data` list.\n",
    "        start_block_num = 16086234\n",
    "        end_block_num = 16093396\n",
    "        duration = 50\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        graph_edges=get_edge_index()\n",
    "\n",
    "        for blocknumber in tqdm(range(start_block_num,end_block_num)):\n",
    "            data = Data(edge_index=graph_edges,x=get_x(blocknumber),y=get_y(blocknumber,duration))\n",
    "            data_list.append(data)\n",
    "            blocknumber+=duration\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "dataset=MyOwnDataset('dataset')\n",
    "# process data and save\n",
    "dataset.process()\n",
    "print('process finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29821dc9ed35f9127746ca55be02d557116051e5e53a5e068671a8692a213485"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
